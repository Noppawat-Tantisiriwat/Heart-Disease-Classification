{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from collections import OrderedDict\n",
    "import hiddenlayer as hl\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset : load using pandas\n",
    "\n",
    "class HeartDiseaseDatasets(Dataset):\n",
    "\n",
    "        def __init__(self):\n",
    "            \n",
    "            training = pd.read_csv(\"heart_train.csv\", index_col=\"Unnamed: 0\", dtype=np.float32).values\n",
    "            #testing = pd.read_csv(\"heart_train.csv\", index_col=\"Unnamed: 0\").values\n",
    "\n",
    "            self.n_train = training.shape[0]\n",
    "            #self.n_test = testing.shape[0]\n",
    "\n",
    "            X_train = training[..., :-1] #, testing[..., :-1]\n",
    "\n",
    "            y_train = training[..., np.newaxis, -1] #, testing[..., [-1]] # target is the last column\n",
    "\n",
    "            self.X_train = X_train\n",
    "\n",
    "            self.y_train = y_train\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return self.X_train[index], self.y_train[index]\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.n_train           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HeartDiseaseDatasets()\n",
    "\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=dataset, \n",
    "                            batch_size=64,\n",
    "                            shuffle=True,\n",
    "                            num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model : subclassing \n",
    "\n",
    "class HeartDiseaseClassifier(nn.Module):\n",
    "\n",
    "    # initialize model and its layers \n",
    "    def __init__(self, input_shape, output_shape, hiddens : List):\n",
    "        super(HeartDiseaseClassifier, self).__init__()\n",
    "        # inherit __init__ from nn.Module\n",
    "        self.input_layer = nn.Linear(input_shape, hiddens[0]) \n",
    "        # an input layer -> corresponding to the input shape\n",
    "        self.hidden_layers = nn.Sequential(OrderedDict([(f\"hidden{i+1}\",nn.Linear(hiddens[i], hiddens[i+1])) for i in range(len(hiddens) - 1)]))\n",
    "        # the use of sequential model make us enable to add multiple hidden layers w/o hard coding\n",
    "        self.output_layer = nn.Linear(hiddens[-1], output_shape)\n",
    "        # output layer\n",
    "        self.activation = nn.ReLU()\n",
    "        # non-linear activation for layers\n",
    "        self.classifier_activation = nn.Sigmoid()\n",
    "        # non-linear activation for last classifier layer\n",
    "    def forward(self, x):\n",
    "        # define forward pass of the model\n",
    "        x = self.activation(self.input_layer(x))\n",
    "        # the first layer then non-linear activation\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            # loop through the sequential and add activation to the hidden outputs\n",
    "            x = self.activation(hidden_layer(x))\n",
    "        # finally, add sigmoid to the final layer\n",
    "        x = self.classifier_activation(self.output_layer(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def fit(self, dataloader, epochs=1, optimizer=None, criterion=None, device=None, lr=0.001):\n",
    "        # define training function\n",
    "        # defining optimizer : the algorithm that optimize the model parameters\n",
    "        _optimizer = optimizer(self.parameters(), lr=lr)\n",
    "        reported_loss = []\n",
    "        for epoch in range(epochs):\n",
    "            collective_loss = []\n",
    "            for _, (features, labels) in tqdm(enumerate(dataloader)):\n",
    "                \n",
    "                # load the data (features and labels) to a particular device\n",
    "                features.to(device)\n",
    "                labels.to(device)\n",
    "\n",
    "                # forward passing\n",
    "\n",
    "                prediction = self.forward(features)\n",
    "                loss = criterion(prediction, labels)\n",
    "\n",
    "                # backward passing\n",
    "\n",
    "                _optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                _optimizer.step()\n",
    "\n",
    "                collective_loss.append(loss.item())\n",
    "            \n",
    "            reported_loss.append(np.mean(collective_loss))\n",
    "            print(f\"epoch {epoch+1} finished!\", f\"loss = {np.mean(collective_loss)}\")\n",
    "\n",
    "        print(\"Training finished!\")\n",
    "\n",
    "        return np.array(reported_loss)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HeartDiseaseClassifier(dataset.X_train.shape[1], 1, [10, 5, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing model \n",
    "transforms = [hl.transforms.Prune('Constant')] # Removes Constant nodes from graph.\n",
    "\n",
    "with torch.no_grad():\n",
    "    graph = hl.build_graph(model, torch.zeros([1, 13]), transforms=transforms)\n",
    "    graph.theme = hl.graph.THEMES['blue'].copy()\n",
    "    graph.save('HeartDisease_hiddenlayer', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "model.fit(train_loader, epochs=1000, optimizer=torch.optim.Adam, criterion=nn.BCELoss(), device=device, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeartDiseaseTest(Dataset):\n",
    "\n",
    "        def __init__(self):\n",
    "            \n",
    "            testing = pd.read_csv(\"heart_test.csv\", index_col=\"Unnamed: 0\", dtype=np.float32).values\n",
    "            #testing = pd.read_csv(\"heart_train.csv\", index_col=\"Unnamed: 0\").values\n",
    "\n",
    "            self.n_test = testing.shape[0]\n",
    "            #self.n_test = testing.shape[0]\n",
    "\n",
    "            X_test = testing[..., :-1] \n",
    "\n",
    "            y_test = testing[..., np.newaxis,-1] \n",
    "\n",
    "            self.X_test = X_test\n",
    "\n",
    "            self.y_test = y_test\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return self.X_test[index], self.y_test[index]\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.n_test           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset  =HeartDiseaseTest()\n",
    "test_loader = DataLoader(testset,\n",
    "                        batch_size=128,\n",
    "                        shuffle=True,\n",
    "                        num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_decoding(logit):\n",
    "    logit = torch.where(logit >= 0.5, torch.ones(logit.shape,dtype=torch.float32), logit)\n",
    "    logit = torch.where(logit < 0.5, torch.zeros(logit.shape,dtype=torch.float32), logit)\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = torch.randn([3, 3, 3], dtype=torch.float32)\n",
    "\n",
    "logits_decoding(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "\n",
    "    for features, labels in test_loader:\n",
    "        features.to(device)\n",
    "        labels.to(device)\n",
    "\n",
    "        logit = model(features)\n",
    "        prediction = logits_decoding(logit)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (prediction == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * n_correct / n_samples\n",
    "    print(accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dcacb0086e9a4f4eabd41c33bf4faac5ea0a3337ed3f5eff0680afa930572c04"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
